{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b00e0d07-e7c3-495e-9b01-6a6abc8e53f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11548"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "spark.stop()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d63637-0e89-4268-a798-95f5660c90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a1859a-fb4d-4a08-b449-c2ed177f1732",
   "metadata": {},
   "source": [
    "### Downloading Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3c79e7-8859-4c19-80ea-da5c56732c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading data\n",
    "def downloadData(path):\n",
    "    for url in range(1,13):\n",
    "        # construct file url for 2023 \n",
    "        url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-{url:02}.parquet\"\n",
    "        file_path = path + os.path.basename(url)\n",
    "        # Ensure the parent directory exists\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        if  os.path.exists(file_path):\n",
    "            print(f\"File {file_path} exist.\")\n",
    "            continue  # Skip the current iteration and go to the next file\n",
    "        \n",
    "        # get request to download the file\n",
    "        with requests.get(url , stream=True)as r:\n",
    "            r.raise_for_status()\n",
    "            # write file in chunks\n",
    "            print(f'Writting file to {file_path}')\n",
    "            with open(file_path,\"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=80000):\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6baeee9-cd9f-423b-8557-95ea99f17355",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/itversity/itversity-material/NYC_TCL/data/\" \n",
    "downloadData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d7b652-cdfe-4584-9c23-36907cd2de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download taxi_zone_lookup.csv\n",
    "url=\"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "file_path = path + os.path.basename(url)\n",
    "with requests.get(url , stream=True)as r:\n",
    "            r.raise_for_status()\n",
    "            # write file in chunks\n",
    "            with open(file_path,\"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=80000):\n",
    "                    f.write(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363ba99-a691-4fcf-ba44-094c2ee6967d",
   "metadata": {},
   "source": [
    "### Moving Data from Local to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a39071a-94bf-4879-85e3-75c17cea0ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving file:yellow_tripdata_2022-01.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-01.parquet \n",
      "moving file:yellow_tripdata_2022-02.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-02.parquet \n",
      "moving file:yellow_tripdata_2022-03.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-03.parquet \n",
      "moving file:yellow_tripdata_2022-04.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-04.parquet \n",
      "moving file:yellow_tripdata_2022-05.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-05.parquet \n",
      "moving file:yellow_tripdata_2022-06.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-06.parquet \n",
      "moving file:yellow_tripdata_2022-07.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-07.parquet \n",
      "moving file:yellow_tripdata_2022-08.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-08.parquet \n",
      "moving file:yellow_tripdata_2022-09.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-09.parquet \n",
      "moving file:yellow_tripdata_2022-10.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-10.parquet \n",
      "moving file:yellow_tripdata_2022-11.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-11.parquet \n",
      "moving file:yellow_tripdata_2022-12.parquet  to \n",
      " /NYC/raw/yellow_tripdata_2022-12.parquet \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-copyFromLocal', '/home/itversity/itversity-material/NYC_TCL/data/taxi_zone_lookup.csv', '/NYC/raw/taxi_zone_lookup.csv'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_dir = \"/home/itversity/itversity-material/NYC_TCL/data/\"\n",
    "hdfs_dir = \"/NYC/raw\"\n",
    "# create parent directory on HDFS if not exist\n",
    "subprocess.run([\"hdfs\",\"dfs\",\"-mkdir\",\"-p\",hdfs_dir])\n",
    "# loop over files and move from local to HDFS\n",
    "for file in range(1,13):\n",
    "    file_path =local_dir + f\"yellow_tripdata_2022-{file:02}.parquet\"\n",
    "    file_name = os.path.basename(f\"{local_dir}yellow_tripdata_2022-{file:02}.parquet\")\n",
    "    hdfs_file_path = os.path.join(hdfs_dir,file_name)\n",
    "    # check if file not found on local \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist. Skipping this file.\")\n",
    "        continue  # Skip the current iteration and go to the next file\n",
    "    print(f\"moving file:{file_name}  to \\n {hdfs_file_path} \")\n",
    "    subprocess.run([\"hdfs\", \"dfs\", \"-copyFromLocal\", file_path, hdfs_file_path])\n",
    "# moving taxi_zone_lookup.csv to HDFS\n",
    "file_path =local_dir + f\"taxi_zone_lookup.csv\"\n",
    "file_name = os.path.basename(f\"{local_dir}taxi_zone_lookup.csv\")\n",
    "hdfs_file_path = os.path.join(hdfs_dir,file_name)\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-copyFromLocal\", file_path, hdfs_file_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc5642-63b3-42c8-bc8f-f867d8759dec",
   "metadata": {},
   "source": [
    "### Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd75623-413b-4352-befe-f7ca68027bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * # year,month,dayofyear,datediff,unix_timestamp,dayofmonth,to_date,date_format,round,col\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.types import StructType, StructField, LongType, TimestampType, DoubleType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e52efc4-86ad-4bf9-a301-7bab7a52ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"NYC_taxi\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c45be-c19c-45ba-b0ee-25b2cea53661",
   "metadata": {},
   "source": [
    "### Reading files and saving as one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4f6102b-5dba-41c8-8b47-abcfb883c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/NYC/raw/yellow_tripdata_2022*.parquet\",compression=\"snappy\" )\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aef84ee1-9a24-4c4b-b19f-73de2dc5227a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>total_amount</th></tr>\n",
       "<tr><td>count</td><td>37315145</td><td>37315145</td><td>37315145</td><td>37315145</td><td>37315145</td><td>37315145</td><td>37315145</td></tr>\n",
       "<tr><td>mean</td><td>1.442238077863559</td><td>5.691385983689089</td><td>1.3448498458199747</td><td>164.9714783635438</td><td>162.73626528853097</td><td>1.2206806378482518</td><td>21.602135243734228</td></tr>\n",
       "<tr><td>stddev</td><td>0.947547130371869</td><td>7.162479882767672</td><td>5.278042280257353</td><td>64.82981528797151</td><td>70.13817852868611</td><td>0.4566393943738757</td><td>16.83831250905367</td></tr>\n",
       "<tr><td>min</td><td>1.0</td><td>0.512</td><td>1.0</td><td>1</td><td>1</td><td>1</td><td>0.3</td></tr>\n",
       "<tr><td>25%</td><td>1.0</td><td>1.8399999999999999</td><td>1.0</td><td>132</td><td>113</td><td>1</td><td>12.3</td></tr>\n",
       "<tr><td>50%</td><td>1.0</td><td>3.04</td><td>1.0</td><td>162</td><td>162</td><td>1</td><td>15.96</td></tr>\n",
       "<tr><td>75%</td><td>2.0</td><td>5.696000000000001</td><td>1.0</td><td>234</td><td>234</td><td>1</td><td>22.8</td></tr>\n",
       "<tr><td>max</td><td>9.0</td><td>149.872</td><td>99.0</td><td>265</td><td>265</td><td>5</td><td>408.32900228775395</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+\n",
       "|summary|  passenger_count|     trip_distance|        RatecodeID|     PULocationID|      DOLocationID|      payment_type|      total_amount|\n",
       "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+\n",
       "|  count|         37315145|          37315145|          37315145|         37315145|          37315145|          37315145|          37315145|\n",
       "|   mean|1.442238077863559| 5.691385983689089|1.3448498458199747|164.9714783635438|162.73626528853097|1.2206806378482518|21.602135243734228|\n",
       "| stddev|0.947547130371869| 7.162479882767672| 5.278042280257353|64.82981528797151| 70.13817852868611|0.4566393943738757| 16.83831250905367|\n",
       "|    min|              1.0|             0.512|               1.0|                1|                 1|                 1|               0.3|\n",
       "|    25%|              1.0|1.8399999999999999|               1.0|              132|               113|                 1|              12.3|\n",
       "|    50%|              1.0|              3.04|               1.0|              162|               162|                 1|             15.96|\n",
       "|    75%|              2.0| 5.696000000000001|               1.0|              234|               234|                 1|              22.8|\n",
       "|    max|              9.0|           149.872|              99.0|              265|               265|                 5|408.32900228775395|\n",
       "+-------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741944f-c3fd-4729-b5f0-9314aec70ad0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploring and Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44dc4548-d227-4c95-a5e7-e463d8285792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to focus on necessary features for the analysis some columns will be excluded \n",
    "# assuming trips with distance greater than 150 or less than 0.5 miles are outliers \n",
    "# assuming trips with total_amount greater than 350 or less than \n",
    "# considering only the absolute value for total_amount \n",
    "required_columns = [\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"trip_distance\",\"RatecodeID\",\n",
    "                    \"PULocationID\",\"DOLocationID\",\"payment_type\",\"total_amount\"]\n",
    "df = df.withColumn(\"total_amount\",abs(format_number(col(\"total_amount\")+col(\"airport_fee\"),2).cast(\"double\"))).select(required_columns) \\\n",
    "        .withColumn(\"trip_distance\" , col(\"trip_distance\")*1.6) \\\n",
    "        .where(\n",
    "                (col(\"trip_distance\")<=150)&(col(\"trip_distance\") >= 0.5)\n",
    "                ) \\\n",
    "        .where(\n",
    "                (col(\"total_amount\") <=350)\n",
    "                )\n",
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0f2151d-1539-4416-96b4-f0ddff7b8ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to count null values for each column containing nulls\n",
    "def null_count(df):\n",
    "    null_columns_count=[]\n",
    "    row_count=df.count()\n",
    "    for c in df.columns:\n",
    "        null_rows=df.where(df[f\"{c}\"].isNull()).count()\n",
    "        if null_rows > 0:\n",
    "            temp= c, null_rows , (null_rows/row_count)*100\n",
    "            null_columns_count.append(temp)\n",
    "            \n",
    "    return null_columns_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6639e656-5353-4fa4-8139-0250b3a91563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "null_columns = null_count(df)\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d624-2e9c-4dfb-8802-87cf8159dcdf",
   "metadata": {},
   "source": [
    "##### Substituting  records containing nulls for \"passenger_count\" column with AVG number of passenger per trip\n",
    "##### Substituting  records containing nulls for \"total_amount\" column using a factor of \"fare_per_distance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56df62ae-4a27-4f53-929c-94bc4e2989e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average passenger count per trip  \n",
    "avg_passenger_count = df.select(\"passenger_count\").where((col(\"passenger_count\").isNotNull()) & (col(\"passenger_count\")!= 0) ). \\\n",
    "        select(ceil(avg(\"passenger_count\"))).collect()[0][0]\n",
    "# Calculate factor for fare per distance\n",
    "avg_fare_trip = df.select([\"trip_distance\",\"total_amount\"]).where(\n",
    "            (col(\"trip_distance\").isNotNull())|(col(\"trip_distance\")!=0) | (col(\"total_amount\").isNotNull())|(col(\"total_amount\")!=0)) \\\n",
    "            .withColumn(\"fare_per_trip\", col(\"total_amount\")/col(\"trip_distance\")).agg(avg(\"fare_per_trip\")).collect()[0][0]\n",
    "\n",
    "# handling nulls in columns passenger_count & total_amount\n",
    "df=df.withColumn(\"passenger_count\", \\\n",
    "                when(\n",
    "    (col(\"passenger_count\").isNull())|(col(\"passenger_count\")==0),lit(avg_passenger_count)).otherwise(col(\"passenger_count\"))) \\\n",
    "    .withColumn(\"total_amount\" ,\n",
    "               when((col(\"total_amount\").isNull()) | (col(\"total_amount\")==0), col(\"trip_distance\")*avg_fare_trip ).otherwise(col(\"total_amount\")) )\n",
    "# df.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cc699-883d-41e5-856e-82a0c5bf5dc8",
   "metadata": {},
   "source": [
    "##### Chechk if any integer field contains negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72f2dddc-eba6-47c9-981c-c81eba0f87ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integr_fields =[field.name for field in df.schema if isinstance(field.dataType , (LongType, DoubleType))  ]\n",
    "negative_values = {column: df.select(column).where(col(column) < 0).count() > 0 for column in integr_fields  }\n",
    "negative_values=[column  for column , has_negative in negative_values.items() if has_negative]\n",
    "negative_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fc3c9ec-ba01-4a12-8837-183978e9ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the absolute for any negative value \n",
    "for column in negative_values:\n",
    "    df = df.withColumn(column,abs(col(column)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6dbf28c-a91e-45f6-bc5c-efe83dfbf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_arranged=[\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"trip_distance\",\n",
    "                  \"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"duration\",\"payment_type\",\"total_amount\",\"year\",\"month\",\"day\",\"day_name\"]\n",
    "df_final =df.withColumn(\"trip_distance\",round(col(\"trip_distance\"),2)) \\\n",
    "        .withColumn(\"year\", year(\"tpep_pickup_datetime\").cast(\"string\")) \\\n",
    "        .withColumn(\"month\",month(\"tpep_pickup_datetime\").cast(\"string\")) \\\n",
    "        .withColumn(\"day\",dayofmonth(\"tpep_pickup_datetime\").cast(\"string\")) \\\n",
    "        .withColumn(\"day_name\",date_format(\"tpep_pickup_datetime\" , \"E\")) \\\n",
    "        .withColumn(\"duration\",(unix_timestamp(\"tpep_dropoff_datetime\")-unix_timestamp(\"tpep_pickup_datetime\"))/60) \\\n",
    "        .withColumn(\"duration\", round(\"duration\",2)) \\\n",
    "            .select(columns_arranged).where(col(\"year\")=='2022')  # filtring for year 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be85f9eb-8f1c-4646-9a09-836fe2bd0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.write.partitionBy(\"year\",\"month\").mode(\"overwrite\").format(\"parquet\").saveAsTable(\"Yellow_tripdata_cleaned\",path=\"/NYC/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957f652-9e65-4716-bd6d-e65b72cbc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "# df.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
